{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0097248e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Sentiment Analysis Task : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b91313b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1 star, with score: 0.2821\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\",model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "result = nlp(\"أكره\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee2f548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5 stars, with score: 0.6703\n"
     ]
    }
   ],
   "source": [
    "result = nlp(\"je suis heureux\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888e222",
   "metadata": {},
   "source": [
    "## Text Generator Task :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a204b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4468867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'مرحبا كيف حالك؟ كيف يمكن ان يكون هناك بعض من الممكن ان تكون هناك بعض من الممكن ان تكون هذه الرواية من الممكن ان تكون افضل من ذلك\"\\n\"لم تعجبني كثيراً و لكن لم تعجبني بعض القصص التي أعجبتني و لكن لم تعجبني بعض القصص'}]\n"
     ]
    }
   ],
   "source": [
    "text_generator_AR = pipeline(\"text-generation\",model=\"mofawzy/gpt2-arabic-sentence-generator\")\n",
    "print(text_generator_AR(\"مرحبا كيف حالك\", max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d517f8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"je m'encharge de vous faire part de mon expérience . Il est donc important de bien choisir son matériel . Il est donc important de bien choisir son matériel . Il est donc important de bien choisir son matériel de ski . Il est donc important de\"}]\n"
     ]
    }
   ],
   "source": [
    "text_generator_FR = pipeline(\"text-generation\",model=\"antoiloui/belgpt2\")\n",
    "print(text_generator_FR(\"je m'encharge\", max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b5f0a",
   "metadata": {},
   "source": [
    "## Named Entity Recognition :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f900b598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3892483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0adf8123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.83755845,\n",
       "  'index': 23,\n",
       "  'word': 'Al',\n",
       "  'start': 58,\n",
       "  'end': 60},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.37570736,\n",
       "  'index': 24,\n",
       "  'word': '##mo',\n",
       "  'start': 60,\n",
       "  'end': 62},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.35866955,\n",
       "  'index': 25,\n",
       "  'word': '##had',\n",
       "  'start': 62,\n",
       "  'end': 65},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9979783,\n",
       "  'index': 27,\n",
       "  'word': 'Abd',\n",
       "  'start': 67,\n",
       "  'end': 70},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99057466,\n",
       "  'index': 28,\n",
       "  'word': '##el',\n",
       "  'start': 70,\n",
       "  'end': 72},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.91506726,\n",
       "  'index': 29,\n",
       "  'word': '##mo',\n",
       "  'start': 72,\n",
       "  'end': 74},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9212709,\n",
       "  'index': 30,\n",
       "  'word': '##ume',\n",
       "  'start': 74,\n",
       "  'end': 77},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9278313,\n",
       "  'index': 31,\n",
       "  'word': '##n',\n",
       "  'start': 77,\n",
       "  'end': 78},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99709344,\n",
       "  'index': 41,\n",
       "  'word': 'Mar',\n",
       "  'start': 99,\n",
       "  'end': 102},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.997189,\n",
       "  'index': 42,\n",
       "  'word': '##rak',\n",
       "  'start': 102,\n",
       "  'end': 105},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.998302,\n",
       "  'index': 43,\n",
       "  'word': '##ech',\n",
       "  'start': 105,\n",
       "  'end': 108},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.2587625,\n",
       "  'index': 69,\n",
       "  'word': 'Cell',\n",
       "  'start': 177,\n",
       "  'end': 181},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.53457355,\n",
       "  'index': 70,\n",
       "  'word': '##e',\n",
       "  'start': 181,\n",
       "  'end': 182},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99957734,\n",
       "  'index': 95,\n",
       "  'word': 'Ya',\n",
       "  'start': 241,\n",
       "  'end': 243},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9066135,\n",
       "  'index': 96,\n",
       "  'word': '##co',\n",
       "  'start': 243,\n",
       "  'end': 245},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9984366,\n",
       "  'index': 97,\n",
       "  'word': '##ub',\n",
       "  'start': 245,\n",
       "  'end': 247},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9989232,\n",
       "  'index': 98,\n",
       "  'word': 'Al',\n",
       "  'start': 248,\n",
       "  'end': 250},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.56176335,\n",
       "  'index': 99,\n",
       "  'word': '-',\n",
       "  'start': 250,\n",
       "  'end': 251},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99814755,\n",
       "  'index': 100,\n",
       "  'word': 'Mans',\n",
       "  'start': 251,\n",
       "  'end': 255},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.965883,\n",
       "  'index': 101,\n",
       "  'word': '##our',\n",
       "  'start': 255,\n",
       "  'end': 258},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.33260003,\n",
       "  'index': 116,\n",
       "  'word': 'La',\n",
       "  'start': 309,\n",
       "  'end': 311},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.727986,\n",
       "  'index': 117,\n",
       "  'word': 'Ko',\n",
       "  'start': 312,\n",
       "  'end': 314},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.4570826,\n",
       "  'index': 118,\n",
       "  'word': '##uto',\n",
       "  'start': 314,\n",
       "  'end': 317},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.5264732,\n",
       "  'index': 119,\n",
       "  'word': '##ubi',\n",
       "  'start': 317,\n",
       "  'end': 320}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline('ner')\n",
    "nlp(\"Une première mosquée fut construite en 1148 par le sultan Almohade Abdelmoumen après avoir conquis Marrakech.\" \"Il reconstruira une deuxième version de taille semblable vers 1158. Celle-ci est la version actuelle, la première ayant été démolie.\"\n",
    "\"Yacoub Al-Mansour finalisera la construction du minaret vers 1195.3 La Koutoubia est considérée comme un important exemple d'architecture almohade et de l'architecture des mosquées marocaines de manière générale.\"\n",
    "\"3 Le minaret de 77 mètres est décoré de différents motifs géométriques et surmonté d'une flèche et d'orbes métalliques. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76155fb7",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33a1410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f79c6a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c7cc75f98c4e3dbdfb2ce5c302f98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436c686849364aeb9b1b81f7efc6ebd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5fa15cf3b04889bfcda0c7b066898b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9ac8bf1d0941fab87e812cc40f13ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9856a8fe28e49f29331028dc2e8a502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4097e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\" Reprendre la rhétorique comme grille d’analyse et comme fondement de l’écriture scientifique peut sembler périlleux dans un pays comme la France, qui a banni l’enseignement de cette discipline et occulté le rôle qu’elle joue dans l’élaboration des discours depuis les assauts de Descartes et de Pierre de la Ramée contre elle. Cependant, les éléments de cet antique art du discours sont bien d’actualité et fournissent des outils efficaces pour détailler avec finesse les processus de création, de mise en forme et de diffusion du savoir entre scientifiques, ce qui doit permettre d’appréhender l’évolution des formes d’édition, du livre au numérique. Ses présupposés, son rôle apparaissent utiles dans le monde actuel : il faut considérer que c’est une « technique » à part entière et c’est sur elle que reposent les fondations de l’organisation du contenu des discours et ensuite de leur mise en forme.\n",
    "Il faut élucider les rapports entre les sciences humaines et sociales (SHS), ses différents domaines, les caractéristiques scientifiques du discours, l’argumentation, les formats de diffusion et les publics de réception. La question est posée de savoir quels sont les contenus scientifiques, spécifiques aux sciences humaines pour la recherche ou la diffusion de théories en SHS (Sokal, 1996 ; Gardin, 1974 ; Lepenies, 1990).\n",
    "Si l’on cherche quelle est la norme de communication établie depuis des siècles, on peut établir que les discours en SHS sont des objets réglés par le système rhétorique (Delmotte, 2007). L’édition numérique est fréquemment présentée comme une « révolution », cependant elle semble marquée par la tradition rhétorique qui est transposée sur les portails institutionnels de diffusion de ressources électroniques. Une réflexion doit être menée pour répondre aux besoins de la communication médiatisée par internet et la question se pose alors de savoir quelles « normes » et quels standards doivent être envisagés. Pour répondre à cette problématique, il est essentiel d’insister sur la nécessité de penser avant tout l’organisation du discours lui-même avant la mise en œuvre de « technologies de l’information et de la communication ». Une norme du discours de science existe et il est alors incontournable de revenir aux notions qui la fondent. Revenir aux définitions des concepts de logique, de rhétorique et d’argumentation est nécessaire et il faut alors s’attacher à les définir le plus précisément possible ainsi que leur rôle.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92d8ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \" Reprendre la rhétorique comme grille d’analyse et comme fondement de l’écriture scientifique peut sembler périlleux dans un pays comme la France . Céléments de cet antique art du discours sont bien d'actualité and fournissent des outils .\"}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(ARTICLE, max_length=100, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a7b675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5803408c74f6450188331ea206ed76cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd817f9b76bb4acfaa65d2f4337d9363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74563aefd72644da825bb7f90085cbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95aeadef867c4703b956a3c5577b3580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f75c7c2cef47daaded6782ed296be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d91e3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_article=\"\"\" تشير التقديرات إلى أن ما يزيد قليلا على نصف مليون شخص يتحدثون اللغة النوبية اليوم، ورغم أن الأبجدية الأصلية كانت تستخدم باستمرار لكتابة اللغة النوبية القديمة حتى انهيار آخر مملكة نوبية في القرن 16، فلا يزال كثير من الناس يعتقدون أن اللغات النوبية غير مكتوبة إلى يومنا هذا.\n",
    "بعد مرور أكثر من نصف قرن على تهجير النوبيين المصريين من قراهم في جنوبي مصر عقب بناء السد العالي وخزان أسوان في ستينيات القرن الماضي، يخوض النوبيون نضالا جديدا للحفاظ على لغتهم الأم بين الأجيال الجديدة.\n",
    "ويعيش كثير من النوبيين مشكلة \"ازدواجية اللغة\"، إذ بحكم انخراطهم في المجتمع يتحدثون اللغة العامية المصرية، ويتلقون تعليمهم في المدارس باللغة العربية، في حين أنهم يتحدثون في ما بينهم بلغتهم الأم.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fabc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"summarize: \" + arabic_article, return_tensors=\"pt\", max_length=512)\n",
    "outputs = model.generate(inputs, early_stopping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd0f77",
   "metadata": {},
   "source": [
    "## Translation Task :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2cdc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634028fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers-4.8.1-py3.8.egg\\transformers\\models\\auto\\modeling_auto.py:843: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2406871143d341cf92a668972c39b15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c4e5a3f8a34969a664881ce6dc8af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/917k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f36f542a3a420193ab934003a002f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\",use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2040610",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"translate English to Arabic: Hugging Face is a technology company based in New York and Paris\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328f61dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> ترجمة إلى العربية: Hugging Face شركة تكنولوجيا مقرها نيويورك وباريس\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e77ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers-4.8.1-py3.8.egg\\transformers\\models\\auto\\modeling_auto.py:843: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc234d3a4fb64445a438d3cc0a14ed26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3e6e9213ef4239bf9df13a8542f25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/311M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef5d30aa378499886bb13fb442d3adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897fd515f22d48feb96ab4804eb230e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/918k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee486ba183054225a308eaaf02f662f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48f9f122129466a81d7f41b5b8943d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-ar-fr\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ar-fr\",use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e020473",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"تعمل مجموعة من المؤلفين والفنانين النوبيين على إصدار كتب مستوحاة من رحلتهم الخاصة في البحث عن ذواتهم، لمساعدة الأطفال على تعلم لغتهم القديمة كتابة ونطقا.\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ef9356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Un groupe d'auteurs et d'artistes nubiens produit des livres inspirés de leur propre voyage pour se retrouver eux-mêmes, afin d'aider les enfants à apprendre par écrit\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae75dfb",
   "metadata": {},
   "source": [
    "## Extractive Question Answering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd71c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b5c244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8987b4a7f50a44c6915da8ed17e64069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09f98f6fd5045f6b5a5696c47ad400a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5772aca0674515ba0031955392f5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c022ffac0845b38f7338b7df8be44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d0ee59c3e34c61bae732541a70a6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51077664",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"\"\"\n",
    "... Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
    "... architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet…) for Natural Language Understanding (NLU) and Natural\n",
    "... Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
    "... TensorFlow 2.0 and PyTorch.\n",
    "... \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6a3344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How many pretrained models are available in Transformers?\",\"What does Transformers provide?\",\"Transformers provides interoperability between which frameworks?\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4569f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many pretrained models are available in 🤗 Transformers?\n",
      "Answer: over 32 +\n",
      "Question: What does 🤗 Transformers provide?\n",
      "Answer: general - purpose architectures\n",
      "Question: 🤗 Transformers provides interoperability between which frameworks?\n",
      "Answer: tensorflow 2. 0 and pytorch\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "\n",
    "    answer_start = torch.argmax(\n",
    "        answer_start_scores\n",
    "     )  # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e601b",
   "metadata": {},
   "source": [
    "## Fill masked Text :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c063fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e41d9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff0f394ab704d86ad65cc37a4a41c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8c533b0bbc45f6bc266df211a43d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb8d563c32749a0a21e64b2f50b4139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee8495058824814ad36c9f13642e95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a031535a7845359fbe6522cfbbf119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1966ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sequence': 'Les coronavirus sont des fins de la famille des Coronaviridae.', 'score': 0.07141315937042236, 'token': 40863, 'token_str': ' fins'}, {'sequence': 'Les coronavirus sont des mutations de la famille des Coronaviridae.', 'score': 0.06041458621621132, 'token': 28513, 'token_str': ' mutations'}, {'sequence': 'Les coronavirus sont des clones de la famille des Coronaviridae.', 'score': 0.046827282756567, 'token': 44001, 'token_str': ' clones'}, {'sequence': 'Les coronavirus sont des parasites de la famille des Coronaviridae.', 'score': 0.04283921420574188, 'token': 37891, 'token_str': ' parasites'}, {'sequence': 'Les coronavirus sont des genes de la famille des Coronaviridae.', 'score': 0.04135967046022415, 'token': 14819, 'token_str': ' genes'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(nlp(f\"Les coronavirus sont des {nlp.tokenizer.mask_token} de la famille des Coronaviridae.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f9c3e",
   "metadata": {},
   "source": [
    "## Feature Extraction Task :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad0485e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2622cd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engineer',\n",
       " 'good',\n",
       " 'interested',\n",
       " 'politics',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " 'software']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"This is a sample sentence\",\n",
    "    \"I am interested in politics\",\n",
    "    \"You are a very good software engineer, engineer.\",]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "vectorizer.fit(sentences)\n",
    "\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb982a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
