{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0097248e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Sentiment Analysis Task : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b91313b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1 star, with score: 0.2821\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\",model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "result = nlp(\"Ø£ÙƒØ±Ù‡\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee2f548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5 stars, with score: 0.6703\n"
     ]
    }
   ],
   "source": [
    "result = nlp(\"je suis heureux\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888e222",
   "metadata": {},
   "source": [
    "## Text Generator Task :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a204b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4468867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ø§Ù† ÙŠÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ Ø¨Ø¹Ø¶ Ù…Ù† Ø§Ù„Ù…Ù…ÙƒÙ† Ø§Ù† ØªÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ Ø¨Ø¹Ø¶ Ù…Ù† Ø§Ù„Ù…Ù…ÙƒÙ† Ø§Ù† ØªÙƒÙˆÙ† Ù‡Ø°Ù‡ Ø§Ù„Ø±ÙˆØ§ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù…ÙƒÙ† Ø§Ù† ØªÙƒÙˆÙ† Ø§ÙØ¶Ù„ Ù…Ù† Ø°Ù„Ùƒ\"\\n\"Ù„Ù… ØªØ¹Ø¬Ø¨Ù†ÙŠ ÙƒØ«ÙŠØ±Ø§Ù‹ Ùˆ Ù„ÙƒÙ† Ù„Ù… ØªØ¹Ø¬Ø¨Ù†ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ù‚ØµØµ Ø§Ù„ØªÙŠ Ø£Ø¹Ø¬Ø¨ØªÙ†ÙŠ Ùˆ Ù„ÙƒÙ† Ù„Ù… ØªØ¹Ø¬Ø¨Ù†ÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ù‚ØµØµ'}]\n"
     ]
    }
   ],
   "source": [
    "text_generator_AR = pipeline(\"text-generation\",model=\"mofawzy/gpt2-arabic-sentence-generator\")\n",
    "print(text_generator_AR(\"Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ\", max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d517f8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"je m'encharge de vous faire part de mon expÃ©rience . Il est donc important de bien choisir son matÃ©riel . Il est donc important de bien choisir son matÃ©riel . Il est donc important de bien choisir son matÃ©riel de ski . Il est donc important de\"}]\n"
     ]
    }
   ],
   "source": [
    "text_generator_FR = pipeline(\"text-generation\",model=\"antoiloui/belgpt2\")\n",
    "print(text_generator_FR(\"je m'encharge\", max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b5f0a",
   "metadata": {},
   "source": [
    "## Named Entity Recognition :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f900b598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3892483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0adf8123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.83755845,\n",
       "  'index': 23,\n",
       "  'word': 'Al',\n",
       "  'start': 58,\n",
       "  'end': 60},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.37570736,\n",
       "  'index': 24,\n",
       "  'word': '##mo',\n",
       "  'start': 60,\n",
       "  'end': 62},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.35866955,\n",
       "  'index': 25,\n",
       "  'word': '##had',\n",
       "  'start': 62,\n",
       "  'end': 65},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9979783,\n",
       "  'index': 27,\n",
       "  'word': 'Abd',\n",
       "  'start': 67,\n",
       "  'end': 70},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99057466,\n",
       "  'index': 28,\n",
       "  'word': '##el',\n",
       "  'start': 70,\n",
       "  'end': 72},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.91506726,\n",
       "  'index': 29,\n",
       "  'word': '##mo',\n",
       "  'start': 72,\n",
       "  'end': 74},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9212709,\n",
       "  'index': 30,\n",
       "  'word': '##ume',\n",
       "  'start': 74,\n",
       "  'end': 77},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9278313,\n",
       "  'index': 31,\n",
       "  'word': '##n',\n",
       "  'start': 77,\n",
       "  'end': 78},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99709344,\n",
       "  'index': 41,\n",
       "  'word': 'Mar',\n",
       "  'start': 99,\n",
       "  'end': 102},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.997189,\n",
       "  'index': 42,\n",
       "  'word': '##rak',\n",
       "  'start': 102,\n",
       "  'end': 105},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.998302,\n",
       "  'index': 43,\n",
       "  'word': '##ech',\n",
       "  'start': 105,\n",
       "  'end': 108},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.2587625,\n",
       "  'index': 69,\n",
       "  'word': 'Cell',\n",
       "  'start': 177,\n",
       "  'end': 181},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.53457355,\n",
       "  'index': 70,\n",
       "  'word': '##e',\n",
       "  'start': 181,\n",
       "  'end': 182},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99957734,\n",
       "  'index': 95,\n",
       "  'word': 'Ya',\n",
       "  'start': 241,\n",
       "  'end': 243},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9066135,\n",
       "  'index': 96,\n",
       "  'word': '##co',\n",
       "  'start': 243,\n",
       "  'end': 245},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9984366,\n",
       "  'index': 97,\n",
       "  'word': '##ub',\n",
       "  'start': 245,\n",
       "  'end': 247},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9989232,\n",
       "  'index': 98,\n",
       "  'word': 'Al',\n",
       "  'start': 248,\n",
       "  'end': 250},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.56176335,\n",
       "  'index': 99,\n",
       "  'word': '-',\n",
       "  'start': 250,\n",
       "  'end': 251},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99814755,\n",
       "  'index': 100,\n",
       "  'word': 'Mans',\n",
       "  'start': 251,\n",
       "  'end': 255},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.965883,\n",
       "  'index': 101,\n",
       "  'word': '##our',\n",
       "  'start': 255,\n",
       "  'end': 258},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.33260003,\n",
       "  'index': 116,\n",
       "  'word': 'La',\n",
       "  'start': 309,\n",
       "  'end': 311},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.727986,\n",
       "  'index': 117,\n",
       "  'word': 'Ko',\n",
       "  'start': 312,\n",
       "  'end': 314},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.4570826,\n",
       "  'index': 118,\n",
       "  'word': '##uto',\n",
       "  'start': 314,\n",
       "  'end': 317},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': 0.5264732,\n",
       "  'index': 119,\n",
       "  'word': '##ubi',\n",
       "  'start': 317,\n",
       "  'end': 320}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline('ner')\n",
    "nlp(\"Une premiÃ¨re mosquÃ©e fut construite en 1148 par le sultan Almohade Abdelmoumen aprÃ¨s avoir conquis Marrakech.\" \"Il reconstruira une deuxiÃ¨me version de taille semblable vers 1158. Celle-ci est la version actuelle, la premiÃ¨re ayant Ã©tÃ© dÃ©molie.\"\n",
    "\"Yacoub Al-Mansour finalisera la construction du minaret vers 1195.3 La Koutoubia est considÃ©rÃ©e comme un important exemple d'architecture almohade et de l'architecture des mosquÃ©es marocaines de maniÃ¨re gÃ©nÃ©rale.\"\n",
    "\"3 Le minaret de 77 mÃ¨tres est dÃ©corÃ© de diffÃ©rents motifs gÃ©omÃ©triques et surmontÃ© d'une flÃ¨che et d'orbes mÃ©talliques. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76155fb7",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33a1410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f79c6a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c7cc75f98c4e3dbdfb2ce5c302f98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436c686849364aeb9b1b81f7efc6ebd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5fa15cf3b04889bfcda0c7b066898b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9ac8bf1d0941fab87e812cc40f13ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9856a8fe28e49f29331028dc2e8a502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4097e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\" Reprendre la rhÃ©torique comme grille dâ€™analyse et comme fondement de lâ€™Ã©criture scientifique peut sembler pÃ©rilleux dans un pays comme la France, qui a banni lâ€™enseignement de cette discipline et occultÃ© le rÃ´le quâ€™elle joue dans lâ€™Ã©laboration des discours depuis les assauts de Descartes et de Pierre de la RamÃ©e contre elle. Cependant, les Ã©lÃ©ments de cet antique art du discours sont bien dâ€™actualitÃ© et fournissent des outils efficaces pour dÃ©tailler avec finesse les processus de crÃ©ation, de mise en forme et de diffusion du savoir entre scientifiques, ce qui doit permettre dâ€™apprÃ©hender lâ€™Ã©volution des formes dâ€™Ã©dition, du livre au numÃ©rique. Ses prÃ©supposÃ©s, son rÃ´le apparaissent utiles dans le monde actuel : il faut considÃ©rer que câ€™est une Â« technique Â» Ã  part entiÃ¨re et câ€™est sur elle que reposent les fondations de lâ€™organisation du contenu des discours et ensuite de leur mise en forme.\n",
    "Il faut Ã©lucider les rapports entre les sciences humaines et sociales (SHS), ses diffÃ©rents domaines, les caractÃ©ristiques scientifiques du discours, lâ€™argumentation, les formats de diffusion et les publics de rÃ©ception. La question est posÃ©e de savoir quels sont les contenus scientifiques, spÃ©cifiques aux sciences humaines pour la recherche ou la diffusion de thÃ©ories en SHS (Sokal, 1996 ; Gardin, 1974 ; Lepenies, 1990).\n",
    "Si lâ€™on cherche quelle est la norme de communication Ã©tablie depuis des siÃ¨cles, on peut Ã©tablir que les discours en SHS sont des objets rÃ©glÃ©s par le systÃ¨me rhÃ©torique (Delmotte, 2007). Lâ€™Ã©dition numÃ©rique est frÃ©quemment prÃ©sentÃ©e comme une Â« rÃ©volution Â», cependant elle semble marquÃ©e par la tradition rhÃ©torique qui est transposÃ©e sur les portails institutionnels de diffusion de ressources Ã©lectroniques. Une rÃ©flexion doit Ãªtre menÃ©e pour rÃ©pondre aux besoins de la communication mÃ©diatisÃ©e par internet et la question se pose alors de savoir quelles Â« normes Â» et quels standards doivent Ãªtre envisagÃ©s. Pour rÃ©pondre Ã  cette problÃ©matique, il est essentiel dâ€™insister sur la nÃ©cessitÃ© de penser avant tout lâ€™organisation du discours lui-mÃªme avant la mise en Å“uvre de Â« technologies de lâ€™information et de la communication Â». Une norme du discours de science existe et il est alors incontournable de revenir aux notions qui la fondent. Revenir aux dÃ©finitions des concepts de logique, de rhÃ©torique et dâ€™argumentation est nÃ©cessaire et il faut alors sâ€™attacher Ã  les dÃ©finir le plus prÃ©cisÃ©ment possible ainsi que leur rÃ´le.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92d8ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \" Reprendre la rhÃ©torique comme grille dâ€™analyse et comme fondement de lâ€™Ã©criture scientifique peut sembler pÃ©rilleux dans un pays comme la France . CÃ©lÃ©ments de cet antique art du discours sont bien d'actualitÃ© and fournissent des outils .\"}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(ARTICLE, max_length=100, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a7b675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5803408c74f6450188331ea206ed76cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd817f9b76bb4acfaa65d2f4337d9363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74563aefd72644da825bb7f90085cbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95aeadef867c4703b956a3c5577b3580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f75c7c2cef47daaded6782ed296be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d91e3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_article=\"\"\" ØªØ´ÙŠØ± Ø§Ù„ØªÙ‚Ø¯ÙŠØ±Ø§Øª Ø¥Ù„Ù‰ Ø£Ù† Ù…Ø§ ÙŠØ²ÙŠØ¯ Ù‚Ù„ÙŠÙ„Ø§ Ø¹Ù„Ù‰ Ù†ØµÙ Ù…Ù„ÙŠÙˆÙ† Ø´Ø®Øµ ÙŠØªØ­Ø¯Ø«ÙˆÙ† Ø§Ù„Ù„ØºØ© Ø§Ù„Ù†ÙˆØ¨ÙŠØ© Ø§Ù„ÙŠÙˆÙ…ØŒ ÙˆØ±ØºÙ… Ø£Ù† Ø§Ù„Ø£Ø¨Ø¬Ø¯ÙŠØ© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙƒØ§Ù†Øª ØªØ³ØªØ®Ø¯Ù… Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ù†ÙˆØ¨ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø­ØªÙ‰ Ø§Ù†Ù‡ÙŠØ§Ø± Ø¢Ø®Ø± Ù…Ù…Ù„ÙƒØ© Ù†ÙˆØ¨ÙŠØ© ÙÙŠ Ø§Ù„Ù‚Ø±Ù† 16ØŒ ÙÙ„Ø§ ÙŠØ²Ø§Ù„ ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ù†Ø§Ø³ ÙŠØ¹ØªÙ‚Ø¯ÙˆÙ† Ø£Ù† Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù†ÙˆØ¨ÙŠØ© ØºÙŠØ± Ù…ÙƒØªÙˆØ¨Ø© Ø¥Ù„Ù‰ ÙŠÙˆÙ…Ù†Ø§ Ù‡Ø°Ø§.\n",
    "Ø¨Ø¹Ø¯ Ù…Ø±ÙˆØ± Ø£ÙƒØ«Ø± Ù…Ù† Ù†ØµÙ Ù‚Ø±Ù† Ø¹Ù„Ù‰ ØªÙ‡Ø¬ÙŠØ± Ø§Ù„Ù†ÙˆØ¨ÙŠÙŠÙ† Ø§Ù„Ù…ØµØ±ÙŠÙŠÙ† Ù…Ù† Ù‚Ø±Ø§Ù‡Ù… ÙÙŠ Ø¬Ù†ÙˆØ¨ÙŠ Ù…ØµØ± Ø¹Ù‚Ø¨ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³Ø¯ Ø§Ù„Ø¹Ø§Ù„ÙŠ ÙˆØ®Ø²Ø§Ù† Ø£Ø³ÙˆØ§Ù† ÙÙŠ Ø³ØªÙŠÙ†ÙŠØ§Øª Ø§Ù„Ù‚Ø±Ù† Ø§Ù„Ù…Ø§Ø¶ÙŠØŒ ÙŠØ®ÙˆØ¶ Ø§Ù„Ù†ÙˆØ¨ÙŠÙˆÙ† Ù†Ø¶Ø§Ù„Ø§ Ø¬Ø¯ÙŠØ¯Ø§ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù„ØºØªÙ‡Ù… Ø§Ù„Ø£Ù… Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¬ÙŠØ§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.\n",
    "ÙˆÙŠØ¹ÙŠØ´ ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ù†ÙˆØ¨ÙŠÙŠÙ† Ù…Ø´ÙƒÙ„Ø© \"Ø§Ø²Ø¯ÙˆØ§Ø¬ÙŠØ© Ø§Ù„Ù„ØºØ©\"ØŒ Ø¥Ø° Ø¨Ø­ÙƒÙ… Ø§Ù†Ø®Ø±Ø§Ø·Ù‡Ù… ÙÙŠ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ ÙŠØªØ­Ø¯Ø«ÙˆÙ† Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ©ØŒ ÙˆÙŠØªÙ„Ù‚ÙˆÙ† ØªØ¹Ù„ÙŠÙ…Ù‡Ù… ÙÙŠ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ÙÙŠ Ø­ÙŠÙ† Ø£Ù†Ù‡Ù… ÙŠØªØ­Ø¯Ø«ÙˆÙ† ÙÙŠ Ù…Ø§ Ø¨ÙŠÙ†Ù‡Ù… Ø¨Ù„ØºØªÙ‡Ù… Ø§Ù„Ø£Ù….\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fabc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"summarize: \" + arabic_article, return_tensors=\"pt\", max_length=512)\n",
    "outputs = model.generate(inputs, early_stopping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd0f77",
   "metadata": {},
   "source": [
    "## Translation Task :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2cdc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634028fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers-4.8.1-py3.8.egg\\transformers\\models\\auto\\modeling_auto.py:843: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2406871143d341cf92a668972c39b15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c4e5a3f8a34969a664881ce6dc8af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/917k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f36f542a3a420193ab934003a002f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\",use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2040610",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"translate English to Arabic: Hugging Face is a technology company based in New York and Paris\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328f61dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> ØªØ±Ø¬Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: Hugging Face Ø´Ø±ÙƒØ© ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ù…Ù‚Ø±Ù‡Ø§ Ù†ÙŠÙˆÙŠÙˆØ±Ùƒ ÙˆØ¨Ø§Ø±ÙŠØ³\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e77ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers-4.8.1-py3.8.egg\\transformers\\models\\auto\\modeling_auto.py:843: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc234d3a4fb64445a438d3cc0a14ed26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3e6e9213ef4239bf9df13a8542f25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/311M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef5d30aa378499886bb13fb442d3adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897fd515f22d48feb96ab4804eb230e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/918k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee486ba183054225a308eaaf02f662f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48f9f122129466a81d7f41b5b8943d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-ar-fr\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ar-fr\",use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e020473",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"ØªØ¹Ù…Ù„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…Ø¤Ù„ÙÙŠÙ† ÙˆØ§Ù„ÙÙ†Ø§Ù†ÙŠÙ† Ø§Ù„Ù†ÙˆØ¨ÙŠÙŠÙ† Ø¹Ù„Ù‰ Ø¥ØµØ¯Ø§Ø± ÙƒØªØ¨ Ù…Ø³ØªÙˆØ­Ø§Ø© Ù…Ù† Ø±Ø­Ù„ØªÙ‡Ù… Ø§Ù„Ø®Ø§ØµØ© ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø°ÙˆØ§ØªÙ‡Ù…ØŒ Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø£Ø·ÙØ§Ù„ Ø¹Ù„Ù‰ ØªØ¹Ù„Ù… Ù„ØºØªÙ‡Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙƒØªØ§Ø¨Ø© ÙˆÙ†Ø·Ù‚Ø§.\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ef9356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Un groupe d'auteurs et d'artistes nubiens produit des livres inspirÃ©s de leur propre voyage pour se retrouver eux-mÃªmes, afin d'aider les enfants Ã  apprendre par Ã©crit\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae75dfb",
   "metadata": {},
   "source": [
    "## Extractive Question Answering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd71c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b5c244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8987b4a7f50a44c6915da8ed17e64069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09f98f6fd5045f6b5a5696c47ad400a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5772aca0674515ba0031955392f5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c022ffac0845b38f7338b7df8be44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d0ee59c3e34c61bae732541a70a6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51077664",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"\"\"\n",
    "... Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
    "... architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
    "... Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
    "... TensorFlow 2.0 and PyTorch.\n",
    "... \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6a3344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How many pretrained models are available in Transformers?\",\"What does Transformers provide?\",\"Transformers provides interoperability between which frameworks?\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4569f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many pretrained models are available in ğŸ¤— Transformers?\n",
      "Answer: over 32 +\n",
      "Question: What does ğŸ¤— Transformers provide?\n",
      "Answer: general - purpose architectures\n",
      "Question: ğŸ¤— Transformers provides interoperability between which frameworks?\n",
      "Answer: tensorflow 2. 0 and pytorch\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "\n",
    "    answer_start = torch.argmax(\n",
    "        answer_start_scores\n",
    "     )  # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e601b",
   "metadata": {},
   "source": [
    "## Fill masked Text :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c063fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e41d9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff0f394ab704d86ad65cc37a4a41c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8c533b0bbc45f6bc266df211a43d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb8d563c32749a0a21e64b2f50b4139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee8495058824814ad36c9f13642e95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a031535a7845359fbe6522cfbbf119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1966ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sequence': 'Les coronavirus sont des fins de la famille des Coronaviridae.', 'score': 0.07141315937042236, 'token': 40863, 'token_str': ' fins'}, {'sequence': 'Les coronavirus sont des mutations de la famille des Coronaviridae.', 'score': 0.06041458621621132, 'token': 28513, 'token_str': ' mutations'}, {'sequence': 'Les coronavirus sont des clones de la famille des Coronaviridae.', 'score': 0.046827282756567, 'token': 44001, 'token_str': ' clones'}, {'sequence': 'Les coronavirus sont des parasites de la famille des Coronaviridae.', 'score': 0.04283921420574188, 'token': 37891, 'token_str': ' parasites'}, {'sequence': 'Les coronavirus sont des genes de la famille des Coronaviridae.', 'score': 0.04135967046022415, 'token': 14819, 'token_str': ' genes'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(nlp(f\"Les coronavirus sont des {nlp.tokenizer.mask_token} de la famille des Coronaviridae.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f9c3e",
   "metadata": {},
   "source": [
    "## Feature Extraction Task :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad0485e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2622cd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engineer',\n",
       " 'good',\n",
       " 'interested',\n",
       " 'politics',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " 'software']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"This is a sample sentence\",\n",
    "    \"I am interested in politics\",\n",
    "    \"You are a very good software engineer, engineer.\",]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "vectorizer.fit(sentences)\n",
    "\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb982a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
